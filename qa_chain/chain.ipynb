{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from embedding.call_embedding import get_embedding\n",
    "load_dotenv()\n",
    "\n",
    "embedding = get_embedding(\"m3e\")\n",
    "persist_directory = '../vector_db/chroma'\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    print(f\"Retrieving information for query: {query}\")\n",
    "    vectordb = Chroma(persist_directory=persist_directory,embedding_function=embedding)\n",
    "    retrieved_docs = vectordb.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "llm=ChatZhipuAI(\n",
    "    model=\"glm-4-long\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    print(response)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "content='Hello! How can I assist you today?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 139, 'total_tokens': 150}, 'model_name': 'glm-4-long', 'finish_reason': 'stop'} id='run-cd2a5139-ec85-49f2-822f-080b396042c6-0'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "什么是蘑菇书(easyrl)？\n",
      "content='' additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"query\": \"什么是蘑菇书(easyrl)？\"}', 'name': 'retrieve'}, 'id': 'call_-8790938269921842468', 'index': 0, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 146, 'total_tokens': 162}, 'model_name': 'glm-4-long', 'finish_reason': 'tool_calls'} id='run-08e21664-ea8b-424c-a237-e2495298a6a4-0' tool_calls=[{'name': 'retrieve', 'args': {'query': '什么是蘑菇书(easyrl)？'}, 'id': 'call_-8790938269921842468', 'type': 'tool_call'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_-8790938269921842468)\n",
      " Call ID: call_-8790938269921842468\n",
      "  Args:\n",
      "    query: 什么是蘑菇书(easyrl)？\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'category': 'Title', 'element_id': 'c77db7741393ef5b11ce8739ce702a69', 'file_directory': './knowledge_db/easy_rl', 'filename': '强化学习入门指南.txt', 'filetype': 'text/plain', 'last_modified': '2025-04-08T10:15:20', 'source': './knowledge_db/easy_rl/强化学习入门指南.txt'}\n",
      "Content: 这本书为什么叫蘑菇书呢\n",
      "\n",
      "Source: {'category': 'Title', 'element_id': '58c7a64380a066d09742906693d128ba', 'file_directory': './knowledge_db/easy_rl', 'filename': '强化学习入门指南.txt', 'filetype': 'text/plain', 'last_modified': '2025-04-08T10:15:20', 'source': './knowledge_db/easy_rl/强化学习入门指南.txt'}\n",
      "Content: 这个蘑菇书它出版的一些故事\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "蘑菇书(easyrl)是一本关于强化学习的入门指南，其名称可能来源于其内容简单易懂，适合初学者。\n"
     ]
    }
   ],
   "source": [
    "input_message = \"什么是蘑菇书(easyrl)？\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "llm_universe是什么？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_-8790921571086572865)\n",
      " Call ID: call_-8790921571086572865\n",
      "  Args:\n",
      "    query: llm_universe是什么\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': './knowledge_db/readme_summary/llm-universe_summary.md'}\n",
      "Content: llm-universe Summary\n",
      "\n",
      "这个仓库名是 llm-universe. 这个仓库主要是关于动手学习大模型应用开发的教程，介绍了大模型的简介、API调用、开发流程、数据库搭建、Prompt设计、验证迭代、前后端开发等内容，旨在帮助小白开发者快速掌握大模型应用开发的基础技能。\n",
      "\n",
      "Source: {'source': './knowledge_db/readme_summary/llms-from-scratch-cn_summary.md'}\n",
      "Content: llms-from-scratch-cn Summary\n",
      "\n",
      "这个仓库名是 llms-from-scratch-cn. 这仓库内容主要是一个详细教程，教你如何从头开始实现类似ChatGPT的大语言模型（LLM）。内容涵盖了编码、预训练和微调过程，适合有编程基础的人深入了解LLM工作原理，并愿意从零开始构建和训练自己的LLM。总体而言，这是一个系统化学习路径，强调实践和深入理解模型原理的项目。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "llm-universe是一个关于动手学习大模型应用开发的教程仓库，旨在帮助小白开发者快速掌握大模型应用开发的基础技能。\n"
     ]
    }
   ],
   "source": [
    "input_message = \"llm_universe是什么？\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "可以详细介绍一下吗\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_-8790933425198111245)\n",
      " Call ID: call_-8790933425198111245\n",
      "  Args:\n",
      "    query: llm-universe\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': './knowledge_db/readme_summary/llm-universe_summary.md'}\n",
      "Content: llm-universe Summary\n",
      "\n",
      "这个仓库名是 llm-universe. 这个仓库主要是关于动手学习大模型应用开发的教程，介绍了大模型的简介、API调用、开发流程、数据库搭建、Prompt设计、验证迭代、前后端开发等内容，旨在帮助小白开发者快速掌握大模型应用开发的基础技能。\n",
      "\n",
      "Source: {'source': './knowledge_db/readme_summary/llms-from-scratch-cn_summary.md'}\n",
      "Content: llms-from-scratch-cn Summary\n",
      "\n",
      "这个仓库名是 llms-from-scratch-cn. 这仓库内容主要是一个详细教程，教你如何从头开始实现类似ChatGPT的大语言模型（LLM）。内容涵盖了编码、预训练和微调过程，适合有编程基础的人深入了解LLM工作原理，并愿意从零开始构建和训练自己的LLM。总体而言，这是一个系统化学习路径，强调实践和深入理解模型原理的项目。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "llm-universe是一个教程仓库，主要内容包括大模型的简介、API调用、开发流程、数据库搭建、Prompt设计、验证迭代、前后端开发等，旨在帮助小白开发者快速掌握大模型应用开发的基础技能。\n"
     ]
    }
   ],
   "source": [
    "input_message = \"可以详细介绍一下吗\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
