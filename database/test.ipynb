{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "# print(sys.path)\n",
    "from embedding.call_embedding import get_embedding\n",
    "from llm.call_llm import parse_llm_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e10ef230a747487f9842e741f4d3f946.qHCWVfDWiUnWOkn8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_llm_api_key(\"zhipuai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/personalhub/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "# embedding = SentenceTransformerEmbeddings(model_name=\"moka-ai/m3e-base\")\n",
    "# embedding = OpenAIEmbeddings()\n",
    "embedding = get_embedding(\"m3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：1640\n"
     ]
    }
   ],
   "source": [
    "persist_directory = '../vector_db/chroma'\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：10\n"
     ]
    }
   ],
   "source": [
    "question=\"llm_universe\"\n",
    "sim_docs = vectordb.similarity_search(question,k=10)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "llm-universe Summary\n",
      "\n",
      "这个仓库名是 llm-universe. 这个仓库主要是关于动手学习大模型应用开发的教程，介绍了大模型的简介、API调用、开发流程、数据库搭建、Prompt设计、验证迭代、前后端开发等内容，旨在帮助小白开发者快速掌握大模型应用开发的基础技能。\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "llms-from-scratch-cn Summary\n",
      "\n",
      "这个仓库名是 llms-from-scratch-cn. 这仓库内容主要是一个详细教程，教你如何从头开始实现类似ChatGPT的大语言模型（LLM）。内容涵盖了编码、预训练和微调过程，适合有编程基础的人深入了解LLM工作原理，并愿意从零开始构建和训练自己的LLM。总体而言，这是一个系统化学习路径，强调实践和深入理解模型原理的项目。\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "llm-research Summary\n",
      "\n",
      "这个仓库名是LLM Research，内容主要是建立LLM领域经典论文解读笔记仓库，旨在方便研究人员快速了解大型语言模型（LLM）领域的重要论文，包括TLDR简版和精读版的解读，以帮助研究人员深入学习和掌握LLM领域的前沿知识。同时，项目团队计划在接下来的三到四个月内撰写和整理大量质量过关的论文笔记。\n",
      "--------------\n",
      "检索到的第3个内容: \n",
      "接下来就到第二部分\n",
      "--------------\n",
      "检索到的第4个内容: \n",
      "然后大家可以在这两个\n",
      "--------------\n",
      "检索到的第5个内容: \n",
      "接下来到最后一部分\n",
      "--------------\n",
      "检索到的第6个内容: \n",
      "llm-deploy Summary\n",
      "\n",
      "这个仓库名是 llm-deploy. 此仓库内容主要是项目介绍、规划和贡献者名单，欢迎参与贡献、反馈问题和交流。涉及项目背景、目录、规划以及贡献者信息等内容。\n",
      "--------------\n",
      "检索到的第7个内容: \n",
      "大家学完这个理论以后\n",
      "--------------\n",
      "检索到的第8个内容: \n",
      "self-llm Summary\n",
      "\n",
      "这个仓库名是 self-llm. 这个仓库内容主要是关于开源大模型食用指南的全流程教程，包括环境配置、部署使用、微调等技能指导，旨在帮助更多人了解和应用开源大模型。\n",
      "--------------\n",
      "检索到的第9个内容: \n",
      "这个例子中，我们指导 LLM 将“是否生气”的情况格式化为布尔值，并输出 JSON 格式。你可以尝试对格式化模式进行各种变化，或者使用完全不同的评论来试验，看看 LLM 是否仍然可以准确地提取这些内容。\n",
      "\n",
      "三、主题推断\n",
      "\n",
      "大型语言模型的另一个很酷的应用是推断主题。假设我们有一段长文本，我们如何判断这段文本的主旨是什么？它涉及了哪些主题？让我们通过以下一段虚构的报纸报道来具体了解一下。\n",
      "\n",
      "```python\n",
      "\n",
      "中文\n",
      "\n",
      "story = \"\"\" 在政府最近进行的一项调查中，要求公共部门的员工对他们所在部门的满意度进行评分。 调查结果显示，NASA 是最受欢迎的部门，满意度为 95％。\n",
      "\n",
      "一位 NASA 员工 John Smith 对这一发现发表了评论，他表示： “我对 NASA 排名第一并不感到惊讶。这是一个与了不起的人们和令人难以置信的机会共事的好地方。我为成为这样一个创新组织的一员感到自豪。”\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content}\", end=\"\\n--------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
